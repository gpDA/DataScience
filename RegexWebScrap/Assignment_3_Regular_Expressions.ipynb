{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dealing with Noisy Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We use Pandas to extract information from Wikipedia page `https://en.wikipedia.org/wiki/List_of_lakes_by_area` about the largest lakes in the world. We want to extract from this web page the list of the lakes and their area.\n",
    "\n",
    "The code below extracts the information from Wikipedia, and generates a CSV file, `largest_lakes.csv` , with the information. (You can also find the `largest_lakes.csv` file attached.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "# Extract the tables that appear in the HTML page, which contain the term \"Water Volume\"\n",
    "tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_lakes_by_area', match = 'Water volume', header=0)\n",
    "# Get the first table from the list of tables extracted from the HTML page, which is the one that we want\n",
    "lakes = tables[0]\n",
    "# Replace the character \\xa0 with space\n",
    "lakes.replace(to_replace = r'\\xa0', value= r' ', regex=True, inplace=True)\n",
    "# Save the Name and Area columns as a CSV file\n",
    "lakes[['Name', 'Area']].to_csv(\"largest_lakes.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you open the file, and you can read its contents in memory, in the `lines` list of strings (one entry per line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(\"largest_lakes.csv\",\"r\")\n",
    "lines = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at the extracted information though, you see that is a bit messy. You see that the names of the lakes have leftovers from footnotes, and the area column contains extra characters that we do not need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Caspian Sea*,\"2 (143,000 sq mi)\"',\n",
       " 'Superior[n 1],\"2 (31,700 sq mi)[14]\"',\n",
       " 'Victoria,\"2 (26,590 sq mi)\"',\n",
       " 'Huron[n 1],\"2 (23,000 sq mi)[14]\"',\n",
       " 'Michigan[n 1],\"2 (22,000 sq mi)[14]\"',\n",
       " 'Tanganyika,\"2 (12,600 sq mi)\"',\n",
       " 'Baikal,\"2 (12,200 sq mi)\"',\n",
       " 'Great Bear Lake,\"2 (12,000 sq mi)\"',\n",
       " 'Malawi,\"2 (11,400 sq mi)\"']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use regular expressions to process the file and create a clean file with the name of the lake, and the area of the lake (in square miles) in the next column. The area column should be an integer (withouts commas). For example, the 10 first lines (listed above) should be transformed into:\n",
    "\n",
    "```\n",
    "Caspian Sea\t143000\n",
    "Superior\t31700\n",
    "Victoria\t26590\n",
    "Huron\t23000\n",
    "Michigan\t22000\n",
    "Tanganyika\t12600\n",
    "Baikal\t12200\n",
    "Great Bear Lake\t12000\n",
    "Malawi\t11400\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caspian Sea\t143000\n",
      "Superior\t31700\n",
      "Victoria\t26590\n",
      "Huron\t23000\n",
      "Michigan\t22000\n",
      "Tanganyika\t12600\n",
      "Baikal\t12200\n",
      "Great Bear Lake\t12000\n",
      "Malawi\t11400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here (It should not be more than 10-15 lines, at most)\n",
    "import re\n",
    "\n",
    "#lake name\n",
    "#^[^,]+\n",
    "#size\n",
    "#\\(([^\\)]+)\\)\n",
    "\n",
    "\n",
    "lakereg = re.compile(r'^[^,][a-zA-Z\" \"]+')\n",
    "sizereg = re.compile(r'\\(([^\\)]+)\\)')\n",
    "\n",
    "st = \"\"\n",
    "for line in lines[1:10]:\n",
    "    lake = lakereg.findall(line)\n",
    "    \n",
    "    st += lake[0]\n",
    "    st += '\\t'\n",
    "    cleansize = sizereg.findall(line)\n",
    "    sizereg1 = re.sub(r'[,]+', \"\", cleansize[0])    \n",
    "    sizereg2 = re.compile('[0-9]+')\n",
    "    size = sizereg2.findall(sizereg1)\n",
    "    st += size[0]\n",
    "    st += '\\n'\n",
    "    \n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Reformatting a Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a file `roster-f2018.txt` that contains the roster of students enrolled in the class.\n",
    "\n",
    "The file contains three **tab-separated** columns: `Section`, `Name`, `Email`. \n",
    "\n",
    "* The `Section` can be either `S1` or `S2`.\n",
    "* The `Name` column has the format [_lastname, firstname middlename_]. Not all students have a middle name listed.\n",
    "* The email is the NYU email of the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"roster-f2018.txt\")\n",
    "lines = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S2\\tThandla,Rajiv\\trt1645@nyu.edu',\n",
       " 'S2\\tTsoi,Ashley Shengqiao\\tast418@nyu.edu',\n",
       " 'S2\\tTurdaliev,Komiljon\\tkt1673@nyu.edu',\n",
       " 'S2\\tVerma,Sunny\\tsv1444@nyu.edu',\n",
       " 'S2\\tXu,Sally Jing\\tsjx203@nyu.edu',\n",
       " 'S2\\tYang,Simon\\tsy1924@nyu.edu',\n",
       " 'S2\\tYao,Karen H\\tkhy236@nyu.edu',\n",
       " 'S2\\tYoon,Paul J\\tpjy226@nyu.edu',\n",
       " 'S2\\tZheng,Kaitlyn H\\tkhz216@nyu.edu',\n",
       " 'S2\\tde Valk,Daniel\\tddv228@nyu.edu']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last 10 lines of the file\n",
    "lines[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are asked to reformat the file. The reformatted file should be tab-separated, and should include five columns:\n",
    "\n",
    "`{section}\\t{email}\\t{first}\\t{middle}\\t{last}`\n",
    "\n",
    "The requirements:\n",
    "* The first column should be `Section`, but instead of the values `S1` and `S2`, should say `Section 1` and `Section 2`, respectively.\n",
    "* The second column should be the `NetId`. For someone with the email `pi1@nyu.edu`, the NetId is `pi1`.\n",
    "* The third column should be the first name of the student.\n",
    "* The fourth column should be the middle name of the student (should be empty when there is no middle name)\n",
    "* The fifth column should be the last name of the student\n",
    "\n",
    "You can see an [example of the reformatted file](https://docs.google.com/spreadsheets/d/10j33VgMU6Kjf1MIUnNWpEKXLjLCNXwxjVkMwDU74n08/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section  \tNetId  \tFirst  \tMiddle\t  Last\n",
      "Section 1\tkcc407\tCai\t     \tKent\n",
      "Section 1\tjmc1250\tChabora\t     \tJason\n",
      "Section 1\tjc7015\tChang\t     \tJonah\n",
      "Section 1\tac6325\tChen\t     \tAmy\n",
      "Section 1\tvc1238\tCherevkov\t     \tVlad\n",
      "Section 1\ttff234\tFarman-Farmaian\t     \tTeymour\n",
      "Section 1\txf365\tFu\t     \tJudy\n",
      "Section 1\tggl245\tGarcia\t     \tGabriel\n",
      "Section 1\twh916\tHou\t     \tWangrui\n",
      "Section 1\tjli232\tIngraham\t     \tJess\n",
      "Section 1\tak5562\tKhosla\t     \tAditya\n",
      "Section 1\tak5635\tKhosla\t     \tArkin\n",
      "Section 1\tpk1676\tKundu\t     \tPratyush\n",
      "Section 1\tal4533\tLakhotia\t     \tAkshat\n",
      "Section 1\tgl1144\tLee\t     \tGP\n",
      "Section 1\tal5361\tLin\t     \tAllen\n",
      "Section 1\tjl7028\tLin\t     \tJonathan\n",
      "Section 1\tyl4042\tLing\t     \tYuheng\n",
      "Section 1\tcol223\tLlacer\tOrayani\tCristina\n",
      "Section 1\trl2838\tLoney\t     \tRahul\n",
      "Section 1\trm4467\tMaeda\t     \tRiku\n",
      "Section 1\tcn1095\tNakajima\t     \tChristie\n",
      "Section 1\tnn1079\tNg\t     \tNicole\n",
      "Section 1\tcro257\tOsufsen\t     \tChris\n",
      "Section 1\tkrp354\tPalmer\t     \tKenton\n",
      "Section 1\ttr1328\tRistova\t     \tTeona\n",
      "Section 1\trr2875\tRub\t     \tRachel\n",
      "Section 1\torr214\tRyan\t     \tOliver\n",
      "Section 1\tls4049\tSakhaie\t     \tLiza\n",
      "Section 1\tjps661\tShah\tParas\tJainam\n",
      "Section 1\tjs9950\tShao\t     \tFaye\n",
      "Section 1\tjs9212\tShi\t     \tJiaxin\n",
      "Section 1\tttt296\tTran\t     \tNhi\n",
      "Section 1\tvw529\tWang\t     \tValerie\n",
      "Section 1\tczw207\tWu\tWen-Zuay\tConnie\n",
      "Section 1\tyx1069\tXin\t     \tXavier\n",
      "Section 1\tly904\tYusufov\t     \tLee\n",
      "Section 1\tyz2812\tZhou\t     \tYuxin\n",
      "Section 2\tda1770\tAbaev\t     \tDavid\n",
      "Section 2\tja2981\tAu\t     \tJoelle\n",
      "Section 2\tnpb260\tBaxi\tPritam\tNeel\n",
      "Section 2\tcc4802\tChang\t     \tCharlie\n",
      "Section 2\tsac746\tChhugani\tAnil\tSreya\n",
      "Section 2\tac6143\tChintalapati\t     \tAnusha\n",
      "Section 2\twc1160\tCho\t     \tTony\n",
      "Section 2\tad3535\tDovzhenko\t     \tArtem\n",
      "Section 2\tjpf409\tFriedman\t     \tJaisal\n",
      "Section 2\tapg357\tGheewala\tP\tArjun\n",
      "Section 2\ttg1393\tGuo\t     \tThomas\n",
      "Section 2\tsh4668\tHuang\t     \tCindy\n",
      "Section 2\tjrj333\tJoshi\tR\tJugal\n",
      "Section 2\tvk981\tKao\t     \tVictor\n",
      "Section 2\twfk221\tKhan\t     \tWally\n",
      "Section 2\tck2344\tKim\t     \tColin\n",
      "Section 2\tsml686\tLee\t     \tMike\n",
      "Section 2\tmm8518\tMalhotra\t     \tMohan\n",
      "Section 2\tgm1936\tMennesson\t     \tGabriel\n",
      "Section 2\tgam409\tMuchtar\tA\tGrace\n",
      "Section 2\tnrp341\tPatel\t     \tNisarg\n",
      "Section 2\tap4470\tPeraza\t     \tAlbert\n",
      "Section 2\tkap587\tPertsovsky\t     \tKevin\n",
      "Section 2\typ884\tPolisetty\t     \tNandan\n",
      "Section 2\tar4883\tReddy\t     \tAbhinav\n",
      "Section 2\tgys230\tShen\t     \tGrant\n",
      "Section 2\tls4081\tShi\t     \tMelody\n",
      "Section 2\tat3074\tTaneja\t     \tAparajita\n",
      "Section 2\trt1645\tThandla\t     \tRajiv\n",
      "Section 2\tast418\tTsoi\tShengqiao\tAshley\n",
      "Section 2\tkt1673\tTurdaliev\t     \tKomiljon\n",
      "Section 2\tsv1444\tVerma\t     \tSunny\n",
      "Section 2\tsjx203\tXu\tJing\tSally\n",
      "Section 2\tsy1924\tYang\t     \tSimon\n",
      "Section 2\tkhy236\tYao\tH\tKaren\n",
      "Section 2\tpjy226\tYoon\tJ\tPaul\n",
      "Section 2\tkhz216\tZheng\tH\tKaitlyn\n",
      "Section 2\tddv228\tde Valk\t     \tDaniel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here (It should not be more than 10-15 lines, at most)\n",
    "import re\n",
    "#Section 1 Section 2\n",
    "#NetId : email address before @\n",
    "#first name \n",
    "#middle name\n",
    "#last name\n",
    "netregex = re.compile(r'.+?(?=@)')\n",
    "\n",
    "\n",
    "st1 = ''\n",
    "cnt = 0\n",
    "for line in lines[1:]:\n",
    "    if cnt == 0:\n",
    "        st1 += 'Section  \\tNetId  \\tFirst  \\tMiddle\\t  Last\\n'\n",
    "    else:\n",
    "        l = line.split(\"\\t\")\n",
    "        if l[0] == 'S1':\n",
    "            st1 += 'Section 1'\n",
    "        else:\n",
    "            st1 += 'Section 2'\n",
    "        st1 += '\\t'\n",
    "        net = netregex.findall(l[2])\n",
    "        st1 += net[0]\n",
    "        st1 += '\\t'\n",
    "        name = l[1].split(',')\n",
    "        fn = name[0]\n",
    "        names = name[1].split(' ')\n",
    "        ln = ''\n",
    "        mn = ''\n",
    "        if len(names) == 2:\n",
    "            ln = names[0]\n",
    "            mn = names[1]\n",
    "        else:\n",
    "            ln = name[1]\n",
    "            mn = '     '\n",
    "        st1 += fn\n",
    "        st1 += '\\t'\n",
    "        st1 += mn\n",
    "        st1 += '\\t'    \n",
    "        st1 += ln \n",
    "        st1 += '\\n'\n",
    "    cnt += 1        \n",
    "print(st1)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Detecting Problematic Data Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to process the official NYPD Complaints dataset (available from the NYC Open Data). The dataset contains all the complaints to NYPD that were reported from 2006 until today (the RPT_DT contains the date when the incident was reported.)\n",
    "\n",
    "The code below fetches the latest version of the dataset from NYC Open Data, and creates a smaller file with just 4 columns: CMPLNT_NUM (the complaint number), RPT_DT (the date the incident was reported), CMPLNT_FR_DT (the date the incident occurred), and CMPLNT_FR_TM (the time the incident occurred)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "# From https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i/data\n",
    "!curl 'https://data.cityofnewyork.us/api/views/qgea-i56i/rows.csv?accessType=DOWNLOAD' -o nypd.csv\n",
    "df = pd.read_csv('nypd.csv')\n",
    "df[['CMPLNT_NUM','RPT_DT','CMPLNT_FR_DT','CMPLNT_FR_TM']].dropna().to_csv(\"nypd_short.csv.gz\", index=False, compression='gzip')\n",
    "del(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads the shortened file in memory (in the `lines` variable). You can take a look at the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open('nypd_short.csv.gz', 'rt') as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CMPLNT_NUM,RPT_DT,CMPLNT_FR_DT,CMPLNT_FR_TM',\n",
       " '101109527,12/31/2015,12/31/2015,23:45:00',\n",
       " '153401121,12/31/2015,12/31/2015,23:36:00',\n",
       " '569369778,12/31/2015,12/31/2015,23:30:00',\n",
       " '968417082,12/31/2015,12/31/2015,23:30:00',\n",
       " '641637920,12/31/2015,12/31/2015,23:25:00',\n",
       " '365661343,12/31/2015,12/31/2015,23:18:00',\n",
       " '608231454,12/31/2015,12/31/2015,23:15:00',\n",
       " '265023856,12/31/2015,12/31/2015,23:15:00',\n",
       " '989238731,12/31/2015,12/31/2015,23:15:00']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our focus for this assignment will be the columns `CMPLNT_FR_DT` and `CMPLNT_FR_TM`, which record the date time that the crime has **occurred**. (Note that the date that the incident was reported and the date the incident has occurred are not necessarily the same, and sometimes it takes years for an incident to be reported.) The date is recorded in the MM/DD/YYYY format, and the time is recorded as a 24-hr time (00:00 to 23:59)\n",
    "\n",
    "Unfortunately, the dataset seems to include some dates in the `CMPLNT_FR_DT` column that are incorrect, and some times in the `CMPLNT_FR_TM` that are incorrect. Your task is to write code that uses regular expressions to detect these entries, and print them out. \n",
    "\n",
    "* You should check the `CMPLNT_FR_DT` column for correctness. In general, any date that is not 19xx or 20xx should be marked as **definitely incorrect**. Dates that are before 1930 (i.e., almost 90 years have passed!) should also be treated as **likely incorrect**.\n",
    "* You should also check the `CMPLNT_FR_TM` column and detect any times that are not following the 24-hr time format (00:00 to 23:59)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect incorrect dates and print out the incorrect lines\n",
    "import re\n",
    "#DT\n",
    "#not 19xE\\x 20xx incorrect\n",
    "#1930 incorrect\n",
    "#FROM_TM  24 hr time format\n",
    "\n",
    "regex = re.compile(r'^[0-9]{2}')\n",
    "\n",
    "for line in lines[1:]:\n",
    "    dta = line.split(\",\")\n",
    "    #not 19xx or 20xx\n",
    "    dt = dta[1]\n",
    "    yrDT = dt.split('/')\n",
    "    yr = yrDT[2]\n",
    "    year = regex.findall(yr)    \n",
    "    #if dates are before 1930\n",
    "    if int(yr) < 1930:\n",
    "        print(line)\n",
    "    #if dates is not 19xx or 20xx\n",
    "    elif year[0] != '19' and year[0] != '20':\n",
    "        print(line)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect incorrect times and print out the incorrect lines\n",
    "import re\n",
    "#check the 24-hr time format\n",
    "regex = re.compile(r'^(24:00|2[0-3]:[0-5][0-9]|[0-1][0-9]:[0-5][0-9])')\n",
    "for line in lines[1:]:\n",
    "    dta = line.split(\",\")\n",
    "    dt = dta[3]\n",
    "    xx = regex.findall(dt)\n",
    "    if not (xx[0] == dt[:5]):\n",
    "        print(line)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
